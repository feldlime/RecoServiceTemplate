{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7_8DlX_2jZzT",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T12:32:12.524590Z",
     "iopub.status.busy": "2023-01-22T12:32:12.523513Z",
     "iopub.status.idle": "2023-01-22T12:32:12.529931Z",
     "shell.execute_reply": "2023-01-22T12:32:12.528298Z",
     "shell.execute_reply.started": "2023-01-22T12:32:12.524533Z"
    },
    "id": "7_8DlX_2jZzT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "IczRXBXHjZzV",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T12:32:13.867299Z",
     "iopub.status.busy": "2023-01-22T12:32:13.866000Z",
     "iopub.status.idle": "2023-01-22T12:32:16.353124Z",
     "shell.execute_reply": "2023-01-22T12:32:16.352004Z",
     "shell.execute_reply.started": "2023-01-22T12:32:13.867251Z"
    },
    "id": "IczRXBXHjZzV"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mA1MfXOnjZzW",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T12:41:13.399626Z",
     "iopub.status.busy": "2023-01-22T12:41:13.398452Z",
     "iopub.status.idle": "2023-01-22T12:41:19.723408Z",
     "shell.execute_reply": "2023-01-22T12:41:19.722114Z",
     "shell.execute_reply.started": "2023-01-22T12:41:13.399496Z"
    },
    "id": "mA1MfXOnjZzW"
   },
   "outputs": [],
   "source": [
    "interactions_df = pd.read_csv('interactions_processed_kion.csv')\n",
    "users_df = pd.read_csv('users_processed_kion.csv')\n",
    "items_df = pd.read_csv('items_processed_kion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "G5cP9QcUjZzW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "execution": {
     "iopub.execute_input": "2023-01-22T12:41:19.726341Z",
     "iopub.status.busy": "2023-01-22T12:41:19.725645Z",
     "iopub.status.idle": "2023-01-22T12:41:19.751544Z",
     "shell.execute_reply": "2023-01-22T12:41:19.750286Z",
     "shell.execute_reply.started": "2023-01-22T12:41:19.726296Z"
    },
    "id": "G5cP9QcUjZzW",
    "outputId": "9fc311f0-6f5b-4327-9bbc-1f6bdee3f918"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-cc1fa8be-27ac-4591-ab96-a1be68ba4ee1\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>last_watch_dt</th>\n",
       "      <th>total_dur</th>\n",
       "      <th>watched_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176549</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>4250</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699317</td>\n",
       "      <td>1659</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>8317</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>656683</td>\n",
       "      <td>7107</td>\n",
       "      <td>2021-05-09</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>864613</td>\n",
       "      <td>7638</td>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>14483</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>964868</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>6725</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc1fa8be-27ac-4591-ab96-a1be68ba4ee1')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-cc1fa8be-27ac-4591-ab96-a1be68ba4ee1 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-cc1fa8be-27ac-4591-ab96-a1be68ba4ee1');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   user_id  item_id last_watch_dt  total_dur  watched_pct\n",
       "0   176549     9506    2021-05-11       4250           72\n",
       "1   699317     1659    2021-05-29       8317          100\n",
       "2   656683     7107    2021-05-09         10            0\n",
       "3   864613     7638    2021-07-05      14483          100\n",
       "4   964868     9506    2021-04-30       6725          100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4omWvMOjZzX",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T12:41:21.721270Z",
     "iopub.status.busy": "2023-01-22T12:41:21.720745Z",
     "iopub.status.idle": "2023-01-22T12:41:22.116852Z",
     "shell.execute_reply": "2023-01-22T12:41:22.115397Z",
     "shell.execute_reply.started": "2023-01-22T12:41:21.721229Z"
    },
    "id": "b4omWvMOjZzX"
   },
   "outputs": [],
   "source": [
    "interactions_df = interactions_df[interactions_df['last_watch_dt'] < '2021-04-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "JAuH-fG0jZzX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-22T12:41:23.195240Z",
     "iopub.status.busy": "2023-01-22T12:41:23.194661Z",
     "iopub.status.idle": "2023-01-22T12:41:23.202760Z",
     "shell.execute_reply": "2023-01-22T12:41:23.201745Z",
     "shell.execute_reply.started": "2023-01-22T12:41:23.195188Z"
    },
    "id": "JAuH-fG0jZzX",
    "outputId": "3e259108-40e9-48fc-c212-1bbd7e9e21a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263874, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rWCoSNwWjZzX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-22T12:41:25.368988Z",
     "iopub.status.busy": "2023-01-22T12:41:25.367925Z",
     "iopub.status.idle": "2023-01-22T12:41:25.558751Z",
     "shell.execute_reply": "2023-01-22T12:41:25.557372Z",
     "shell.execute_reply.started": "2023-01-22T12:41:25.368937Z"
    },
    "id": "rWCoSNwWjZzX",
    "outputId": "c7738105-161d-4c43-9028-21b64809ad04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# users: 86614\n",
      "# users with at least 5 interactions: 14563\n"
     ]
    }
   ],
   "source": [
    "users_interactions_count_df = interactions_df.groupby(['user_id', 'item_id']).size().groupby('user_id').size()\n",
    "print('# users: %d' % len(users_interactions_count_df))\n",
    "users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['user_id']]\n",
    "print('# users with at least 5 interactions: %d' % len(users_with_enough_interactions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "qDCcr1_UjZzY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-22T12:41:27.227318Z",
     "iopub.status.busy": "2023-01-22T12:41:27.226717Z",
     "iopub.status.idle": "2023-01-22T12:41:27.326827Z",
     "shell.execute_reply": "2023-01-22T12:41:27.325761Z",
     "shell.execute_reply.started": "2023-01-22T12:41:27.227269Z"
    },
    "id": "qDCcr1_UjZzY",
    "outputId": "cc44175d-eef0-42b9-839a-4c1a0efa5ce4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of interactions: 263874\n",
      "# of interactions from users with at least 5 interactions: 142670\n"
     ]
    }
   ],
   "source": [
    "print('# of interactions: %d' % len(interactions_df))\n",
    "interactions_from_selected_users_df = interactions_df.merge(users_with_enough_interactions_df, \n",
    "               how = 'right',\n",
    "               left_on = 'user_id',\n",
    "               right_on = 'user_id')\n",
    "print('# of interactions from users with at least 5 interactions: %d' % len(interactions_from_selected_users_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bs9IdB8fjZzY",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T12:41:30.431311Z",
     "iopub.status.busy": "2023-01-22T12:41:30.430823Z",
     "iopub.status.idle": "2023-01-22T12:41:30.436607Z",
     "shell.execute_reply": "2023-01-22T12:41:30.435654Z",
     "shell.execute_reply.started": "2023-01-22T12:41:30.431275Z"
    },
    "id": "bs9IdB8fjZzY"
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "MTW_Y4iOjZzY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "execution": {
     "iopub.execute_input": "2023-01-22T12:41:32.237281Z",
     "iopub.status.busy": "2023-01-22T12:41:32.236079Z",
     "iopub.status.idle": "2023-01-22T12:41:32.403346Z",
     "shell.execute_reply": "2023-01-22T12:41:32.401909Z",
     "shell.execute_reply.started": "2023-01-22T12:41:32.237217Z"
    },
    "id": "MTW_Y4iOjZzY",
    "outputId": "8027a8a8-0bf9-4c97-9b69-5281653709c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique user/item interactions: 142670\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0b587a50-5566-4262-8668-4a8b03cad86f\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>watched_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>849</td>\n",
       "      <td>6.375039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>4345</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>10283</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>12261</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>15997</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>952</td>\n",
       "      <td>6.044394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "      <td>4382</td>\n",
       "      <td>4.954196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>4807</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>10436</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>12132</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b587a50-5566-4262-8668-4a8b03cad86f')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0b587a50-5566-4262-8668-4a8b03cad86f button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0b587a50-5566-4262-8668-4a8b03cad86f');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   user_id  item_id  watched_pct\n",
       "0       21      849     6.375039\n",
       "1       21     4345     6.658211\n",
       "2       21    10283     6.658211\n",
       "3       21    12261     6.658211\n",
       "4       21    15997     6.658211\n",
       "5       32      952     6.044394\n",
       "6       32     4382     4.954196\n",
       "7       32     4807     6.658211\n",
       "8       32    10436     6.658211\n",
       "9       32    12132     6.658211"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def smooth_user_preference(x):\n",
    "    return math.log(1+x, 2)\n",
    "    \n",
    "interactions_full_df = interactions_from_selected_users_df \\\n",
    "                    .groupby(['user_id', 'item_id'])['watched_pct'].sum() \\\n",
    "                    .apply(smooth_user_preference).reset_index()\n",
    "print('# of unique user/item interactions: %d' % len(interactions_full_df))\n",
    "interactions_full_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "wNyqdsCxjZzZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-22T12:41:34.443808Z",
     "iopub.status.busy": "2023-01-22T12:41:34.443346Z",
     "iopub.status.idle": "2023-01-22T12:41:34.651267Z",
     "shell.execute_reply": "2023-01-22T12:41:34.650080Z",
     "shell.execute_reply.started": "2023-01-22T12:41:34.443774Z"
    },
    "id": "wNyqdsCxjZzZ",
    "outputId": "e2a2e169-78ef-4f8e-c099-eb56de49338e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# interactions on Train set: 114136\n",
      "# interactions on Test set: 28534\n"
     ]
    }
   ],
   "source": [
    "interactions_train_df, interactions_test_df = train_test_split(interactions_full_df,\n",
    "                                   stratify=interactions_full_df['user_id'], \n",
    "                                   test_size=0.20,\n",
    "                                   random_state=42)\n",
    "\n",
    "print('# interactions on Train set: %d' % len(interactions_train_df))\n",
    "print('# interactions on Test set: %d' % len(interactions_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "v1M9fBagjZzZ",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T12:41:38.570246Z",
     "iopub.status.busy": "2023-01-22T12:41:38.568905Z",
     "iopub.status.idle": "2023-01-22T12:41:38.583223Z",
     "shell.execute_reply": "2023-01-22T12:41:38.581705Z",
     "shell.execute_reply.started": "2023-01-22T12:41:38.570182Z"
    },
    "id": "v1M9fBagjZzZ"
   },
   "outputs": [],
   "source": [
    "#Indexing by personId to speed up the searches during evaluation\n",
    "interactions_full_indexed_df = interactions_full_df.set_index('user_id')\n",
    "interactions_train_indexed_df = interactions_train_df.set_index('user_id')\n",
    "interactions_test_indexed_df = interactions_test_df.set_index('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "Ra2TntFUjZzZ",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T12:41:42.934656Z",
     "iopub.status.busy": "2023-01-22T12:41:42.934139Z",
     "iopub.status.idle": "2023-01-22T12:41:42.940917Z",
     "shell.execute_reply": "2023-01-22T12:41:42.939611Z",
     "shell.execute_reply.started": "2023-01-22T12:41:42.934617Z"
    },
    "id": "Ra2TntFUjZzZ"
   },
   "outputs": [],
   "source": [
    "def get_items_interacted(person_id, interactions_df):\n",
    "    # Get the user's data and merge in the movie information.\n",
    "    interacted_items = interactions_df.loc[person_id]['item_id']\n",
    "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "xpP7YjhRjZzZ",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T12:41:53.435832Z",
     "iopub.status.busy": "2023-01-22T12:41:53.435366Z",
     "iopub.status.idle": "2023-01-22T12:41:53.455616Z",
     "shell.execute_reply": "2023-01-22T12:41:53.454525Z",
     "shell.execute_reply.started": "2023-01-22T12:41:53.435796Z"
    },
    "id": "xpP7YjhRjZzZ"
   },
   "outputs": [],
   "source": [
    "#Top-N accuracy metrics consts\n",
    "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
    "\n",
    "class ModelEvaluator:\n",
    "\n",
    "    def get_not_interacted_items_sample(self, person_id, sample_size, seed=42):\n",
    "        interacted_items = get_items_interacted(person_id, interactions_full_indexed_df)\n",
    "        all_items = set(articles_df['item_id'])\n",
    "        non_interacted_items = all_items - interacted_items\n",
    "\n",
    "        random.seed(seed)\n",
    "        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
    "        return set(non_interacted_items_sample)\n",
    "\n",
    "    def _verify_hit_top_n(self, item_id, recommended_items, topn):        \n",
    "            try:\n",
    "                index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
    "            except:\n",
    "                index = -1\n",
    "            hit = int(index in range(0, topn))\n",
    "            return hit, index\n",
    "\n",
    "    def evaluate_model_for_user(self, model, person_id):\n",
    "        #Getting the items in test set\n",
    "        interacted_values_testset = interactions_test_indexed_df.loc[person_id]\n",
    "        if type(interacted_values_testset['item_id']) == pd.Series:\n",
    "            person_interacted_items_testset = set(interacted_values_testset['item_id'])\n",
    "        else:\n",
    "            person_interacted_items_testset = set([int(interacted_values_testset['item_id'])])  \n",
    "        interacted_items_count_testset = len(person_interacted_items_testset) \n",
    "\n",
    "        #Getting a ranked recommendation list from a model for a given user\n",
    "        person_recs_df = model.recommend_items(person_id, \n",
    "                                               items_to_ignore=get_items_interacted(person_id, \n",
    "                                                                                    interactions_train_indexed_df), \n",
    "                                               topn=10000000000)\n",
    "\n",
    "        hits_at_5_count = 0\n",
    "        hits_at_10_count = 0\n",
    "        #For each item the user has interacted in test set\n",
    "        for item_id in person_interacted_items_testset:\n",
    "            #Getting a random sample (100) items the user has not interacted \n",
    "            #(to represent items that are assumed to be no relevant to the user)\n",
    "            non_interacted_items_sample = self.get_not_interacted_items_sample(person_id, \n",
    "                                                                          sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS, \n",
    "                                                                          seed=item_id%(2**32))\n",
    "\n",
    "            #Combining the current interacted item with the 100 random items\n",
    "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
    "\n",
    "            #Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
    "            valid_recs_df = person_recs_df[person_recs_df['item_id'].isin(items_to_filter_recs)]                    \n",
    "            valid_recs = valid_recs_df['item_id'].values\n",
    "            #Verifying if the current interacted item is among the Top-N recommended items\n",
    "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
    "            hits_at_5_count += hit_at_5\n",
    "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
    "            hits_at_10_count += hit_at_10\n",
    "\n",
    "        #Recall is the rate of the interacted items that are ranked among the Top-N recommended items, \n",
    "        #when mixed with a set of non-relevant items\n",
    "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
    "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
    "\n",
    "        person_metrics = {'hits@5_count':hits_at_5_count, \n",
    "                          'hits@10_count':hits_at_10_count, \n",
    "                          'interacted_count': interacted_items_count_testset,\n",
    "                          'recall@5': recall_at_5,\n",
    "                          'recall@10': recall_at_10}\n",
    "        return person_metrics\n",
    "\n",
    "    def evaluate_model(self, model):\n",
    "        #print('Running evaluation for users')\n",
    "        people_metrics = []\n",
    "        for idx, person_id in enumerate(tqdm(list(interactions_test_indexed_df.index.unique().values))):\n",
    "            #if idx % 100 == 0 and idx > 0:\n",
    "            #    print('%d users processed' % idx)\n",
    "            person_metrics = self.evaluate_model_for_user(model, person_id)  \n",
    "            person_metrics['user_id'] = person_id\n",
    "            people_metrics.append(person_metrics)\n",
    "        print('%d users processed' % idx)\n",
    "\n",
    "        detailed_results_df = pd.DataFrame(people_metrics) \\\n",
    "                            .sort_values('interacted_count', ascending=False)\n",
    "        \n",
    "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        \n",
    "        global_metrics = {'modelName': model.get_model_name(),\n",
    "                          'recall@5': global_recall_at_5,\n",
    "                          'recall@10': global_recall_at_10}    \n",
    "        return global_metrics, detailed_results_df\n",
    "    \n",
    "model_evaluator = ModelEvaluator()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bt-Ko_HMjZza",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T12:41:57.779034Z",
     "iopub.status.busy": "2023-01-22T12:41:57.777417Z",
     "iopub.status.idle": "2023-01-22T12:41:57.787389Z",
     "shell.execute_reply": "2023-01-22T12:41:57.785909Z",
     "shell.execute_reply.started": "2023-01-22T12:41:57.778960Z"
    },
    "id": "bt-Ko_HMjZza"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ySqiCo5jZza",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T12:42:03.271305Z",
     "iopub.status.busy": "2023-01-22T12:42:03.270810Z",
     "iopub.status.idle": "2023-01-22T12:42:03.278535Z",
     "shell.execute_reply": "2023-01-22T12:42:03.277141Z",
     "shell.execute_reply.started": "2023-01-22T12:42:03.271268Z"
    },
    "id": "6ySqiCo5jZza"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Constants\n",
    "SEED = 42 # random seed for reproducibility\n",
    "LR = 1e-3 # learning rate, controls the speed of the training\n",
    "WEIGHT_DECAY = 0.01 # lambda for L2 reg. ()\n",
    "NUM_EPOCHS = 200 # num training epochs (how many times each instance will be processed)\n",
    "GAMMA = 0.9995 # learning rate scheduler parameter\n",
    "BATCH_SIZE = 3000 # training batch size\n",
    "EVAL_BATCH_SIZE = 3000 # evaluation batch size.\n",
    "DEVICE = 'cuda' #'cuda' # device to make the calculations on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "FtzzvibljZza",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T12:42:05.933060Z",
     "iopub.status.busy": "2023-01-22T12:42:05.931911Z",
     "iopub.status.idle": "2023-01-22T12:42:05.969002Z",
     "shell.execute_reply": "2023-01-22T12:42:05.967458Z",
     "shell.execute_reply.started": "2023-01-22T12:42:05.933000Z"
    },
    "id": "FtzzvibljZza"
   },
   "outputs": [],
   "source": [
    "total_df = interactions_train_df.append(interactions_test_indexed_df.reset_index())\n",
    "total_df['user_id'], users_keys = total_df.user_id.factorize()\n",
    "total_df['item_id'], items_keys = total_df.item_id.factorize()\n",
    "\n",
    "train_encoded = total_df.iloc[:len(interactions_train_df)].values\n",
    "test_encoded = total_df.iloc[len(interactions_train_df):].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "crbEdHiJjZza",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T12:42:09.354000Z",
     "iopub.status.busy": "2023-01-22T12:42:09.352465Z",
     "iopub.status.idle": "2023-01-22T12:42:09.967185Z",
     "shell.execute_reply": "2023-01-22T12:42:09.965725Z",
     "shell.execute_reply.started": "2023-01-22T12:42:09.353932Z"
    },
    "id": "crbEdHiJjZza"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "shape = [int(total_df['user_id'].max()+1), int(total_df['item_id'].max()+1)]\n",
    "X_train = csr_matrix((train_encoded[:, 2], (train_encoded[:, 0], train_encoded[:, 1])), shape=shape).toarray()\n",
    "X_test = csr_matrix((test_encoded[:, 2], (test_encoded[:, 0], test_encoded[:, 1])), shape=shape).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sFeJZsDJjZzb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T12:42:12.745785Z",
     "iopub.status.busy": "2023-01-22T12:42:12.745283Z",
     "iopub.status.idle": "2023-01-22T12:42:12.754320Z",
     "shell.execute_reply": "2023-01-22T12:42:12.752855Z",
     "shell.execute_reply.started": "2023-01-22T12:42:12.745745Z"
    },
    "id": "sFeJZsDJjZzb"
   },
   "outputs": [],
   "source": [
    "# Initialize the DataObject, which must return an element (features vector x and target value y)\n",
    "# for a given idx. This class must also have a length atribute\n",
    "class UserOrientedDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        super().__init__() # to initialize the parent class\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.len = len(X)\n",
    "\n",
    "    def __len__(self): # We use __func__ for implementing in-built python functions\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "AoCCUSpUjZzb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T12:42:16.254953Z",
     "iopub.status.busy": "2023-01-22T12:42:16.254416Z",
     "iopub.status.idle": "2023-01-22T12:42:17.434704Z",
     "shell.execute_reply": "2023-01-22T12:42:17.433103Z",
     "shell.execute_reply.started": "2023-01-22T12:42:16.254903Z"
    },
    "id": "AoCCUSpUjZzb"
   },
   "outputs": [],
   "source": [
    "# Initialize DataLoaders - objects, which sample instances from DataObject-s\n",
    "train_dl = DataLoader(\n",
    "    UserOrientedDataset(X_train),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    UserOrientedDataset(X_test),\n",
    "    batch_size = EVAL_BATCH_SIZE,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "dls = {'train': train_dl, 'test': test_dl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b94CXGocjZzb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T12:53:12.965059Z",
     "iopub.status.busy": "2023-01-22T12:53:12.964527Z",
     "iopub.status.idle": "2023-01-22T12:53:12.975037Z",
     "shell.execute_reply": "2023-01-22T12:53:12.973690Z",
     "shell.execute_reply.started": "2023-01-22T12:53:12.965016Z"
    },
    "id": "b94CXGocjZzb"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_and_out_features = 8287):\n",
    "        super().__init__()\n",
    "        self.in_and_out_features = in_and_out_features\n",
    "        self.hidden_size = 500\n",
    "\n",
    "        self.sequential = nn.Sequential( \n",
    "            nn.Linear(in_and_out_features, self.hidden_size), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(self.hidden_size, in_and_out_features) # Another Linear transformation\n",
    "        )\n",
    "\n",
    "    def forward(self, x): # In the forward function, you define how your model runs, from input to output \n",
    "        x = self.sequential(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aY_vqVZLjZzb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-22T12:54:25.315144Z",
     "iopub.status.busy": "2023-01-22T12:54:25.314623Z",
     "iopub.status.idle": "2023-01-22T12:54:26.136714Z",
     "shell.execute_reply": "2023-01-22T12:54:26.135715Z",
     "shell.execute_reply.started": "2023-01-22T12:54:25.315101Z"
    },
    "id": "aY_vqVZLjZzb"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED) # Fix random seed to have reproducible weights of model layers\n",
    "\n",
    "model = Model()\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Initialize GD method, which will update the weights of the model\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "# Initialize learning rate scheduler, which will decrease LR according to some rule\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=GAMMA)\n",
    "\n",
    "def rmse_for_sparse(x_pred, x_true):\n",
    "    mask = (x_true > 0)\n",
    "    sq_diff = (x_pred * mask - x_true) ** 2\n",
    "    mse = sq_diff.sum() / mask.sum()\n",
    "    return mse ** (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "LdlKerxfjZzb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "execution": {
     "iopub.execute_input": "2023-01-22T12:54:33.544338Z",
     "iopub.status.busy": "2023-01-22T12:54:33.543734Z"
    },
    "id": "LdlKerxfjZzb",
    "outputId": "0bc103bb-151d-449f-b7b2-f670b8970d92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7ca8c168-5fc2-4ba9-a83e-51c83e1005bf\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Test RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.315015</td>\n",
       "      <td>2.295504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.191636</td>\n",
       "      <td>2.224912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.955497</td>\n",
       "      <td>2.108439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.836119</td>\n",
       "      <td>2.027701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.736783</td>\n",
       "      <td>2.026640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>0.288658</td>\n",
       "      <td>1.330020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>0.277917</td>\n",
       "      <td>1.331115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>0.307082</td>\n",
       "      <td>1.330125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>0.302980</td>\n",
       "      <td>1.331673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>0.307337</td>\n",
       "      <td>1.329725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ca8c168-5fc2-4ba9-a83e-51c83e1005bf')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7ca8c168-5fc2-4ba9-a83e-51c83e1005bf button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7ca8c168-5fc2-4ba9-a83e-51c83e1005bf');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     Epoch  Train RMSE  Test RMSE\n",
       "0        0    2.315015   2.295504\n",
       "1        1    2.191636   2.224912\n",
       "2        2    1.955497   2.108439\n",
       "3        3    1.836119   2.027701\n",
       "4        4    1.736783   2.026640\n",
       "..     ...         ...        ...\n",
       "195    195    0.288658   1.330020\n",
       "196    196    0.277917   1.331115\n",
       "197    197    0.307082   1.330125\n",
       "198    198    0.302980   1.331673\n",
       "199    199    0.307337   1.329725\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training loop\n",
    "metrics_dict = {\n",
    "    \"Epoch\": [],\n",
    "    \"Train RMSE\": [],\n",
    "    \"Test RMSE\": [],\n",
    "}\n",
    "\n",
    "# Train loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    metrics_dict[\"Epoch\"].append(epoch)\n",
    "    for stage in ['train', 'test']:\n",
    "        with torch.set_grad_enabled(stage == 'train'): # Whether to start building a graph for a backward pass\n",
    "            if stage == 'train':\n",
    "                model.train() # Enable some \"special\" layers (will speak about later)\n",
    "            else:\n",
    "                model.eval() # Disable some \"special\" layers (will speak about later)\n",
    "\n",
    "            loss_at_stage = 0 \n",
    "            for batch in dls[stage]:\n",
    "                batch = batch.to(DEVICE)\n",
    "                x_pred = model(batch) # forward pass: model(x_batch) -> calls forward()\n",
    "                loss = rmse_for_sparse(x_pred, batch) # ¡Important! y_pred is always the first arg\n",
    "                if stage == \"train\":\n",
    "                    loss.backward() # Calculate the gradients of all the parameters wrt loss\n",
    "                    optimizer.step() # Update the parameters\n",
    "                    scheduler.step()\n",
    "                    optimizer.zero_grad() # Zero the saved gradient\n",
    "                loss_at_stage += loss.item() * len(batch)\n",
    "            rmse_at_stage = (loss_at_stage / len(dls[stage].dataset)) ** (1/2)\n",
    "            metrics_dict[f\"{stage.title()} RMSE\"].append(rmse_at_stage)\n",
    "            \n",
    "    if (epoch == NUM_EPOCHS - 1) or epoch % 10 == 9:\n",
    "        clear_output(wait=True)\n",
    "        display(pd.DataFrame(metrics_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ZXCPjyMajZzb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZXCPjyMajZzb",
    "outputId": "a0448c4f-5e53-409b-c277-fc704e617202"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3084,  2.5601,  1.0144,  ..., -0.0948, -0.1467,  0.3106],\n",
       "        [ 0.1575,  0.8934,  0.1315,  ..., -0.1049,  0.0096,  0.0350],\n",
       "        [ 0.6704,  1.5142,  0.6962,  ..., -0.2259, -0.0353,  0.0676],\n",
       "        ...,\n",
       "        [ 0.3153,  1.1243,  0.1393,  ..., -0.1222, -0.1398,  0.0617],\n",
       "        [ 0.3214,  1.9313,  0.3253,  ..., -0.1548, -0.0918, -0.0392],\n",
       "        [ 0.3434,  0.9318, -0.0341,  ..., -0.1714, -0.0446,  0.1267]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_pred = model(torch.Tensor(X_test).to(DEVICE))\n",
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bkSfO9fgjZzc",
   "metadata": {
    "id": "bkSfO9fgjZzc"
   },
   "outputs": [],
   "source": [
    "class AERecommender:\n",
    "    \n",
    "    MODEL_NAME = 'Autoencoder'\n",
    "    \n",
    "    def __init__(self, X_preds, X_train_and_val, X_test):\n",
    "\n",
    "        self.X_preds = X_preds.cpu().detach().numpy()\n",
    "        self.X_train_and_val = X_train_and_val\n",
    "        self.X_test = X_test\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "        \n",
    "    def recommend_items(self, user_id, items_to_select_idx, topn=10, verbose=False):\n",
    "        user_preds = self.X_preds[user_id][items_to_select_idx]\n",
    "        items_idx = items_to_select_idx[np.argsort(-user_preds)[:topn]]\n",
    "\n",
    "        # Recommend the highest predicted rating movies that the user hasn't seen yet.\n",
    "        return items_idx\n",
    "\n",
    "    def evaluate(self, size=100):\n",
    "\n",
    "        X_total = self.X_train_and_val + self.X_test\n",
    "\n",
    "        true_5 = []\n",
    "        true_10 = []\n",
    "\n",
    "        for user_id in range(len(X_test)):\n",
    "            non_zero = np.argwhere(self.X_test[user_id] > 0).ravel()\n",
    "            all_nonzero = np.argwhere(X_total[user_id] > 0).ravel()\n",
    "            select_from = np.setdiff1d(np.arange(X_total.shape[1]), all_nonzero)\n",
    "\n",
    "            for non_zero_idx in non_zero:\n",
    "                random_non_interacted_100_items = np.random.choice(select_from, size=20, replace=False)\n",
    "                preds = self.recommend_items(user_id, np.append(random_non_interacted_100_items, non_zero_idx), topn=10)\n",
    "                true_5.append(non_zero_idx in preds[:5])\n",
    "                true_10.append(non_zero_idx in preds)\n",
    "\n",
    "        return {\"recall@5\": np.mean(true_5), \"recall@10\": np.mean(true_10)}\n",
    "    \n",
    "ae_recommender_model = AERecommender(X_pred, X_train, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "yRBbD9xmjZzc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yRBbD9xmjZzc",
    "outputId": "d407d2b7-ee44-4299-9b29-046f41deb396"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall@5': 0.08641891035330142, 'recall@10': 0.25274264483602643}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_global_metrics = ae_recommender_model.evaluate()\n",
    "ae_global_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ydc-4MJn-KFM",
   "metadata": {
    "id": "ydc-4MJn-KFM"
   },
   "source": [
    "Проведем эксперименты с моделями и гиперпараметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "GZfxQH7Z-hMK",
   "metadata": {
    "id": "GZfxQH7Z-hMK"
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    torch.manual_seed(SEED) # Fix random seed to have reproducible weights of model layers\n",
    "\n",
    "    model = Model()\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # Initialize GD method, which will update the weights of the model\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    # Initialize learning rate scheduler, which will decrease LR according to some rule\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=GAMMA)\n",
    "\n",
    "\n",
    "    # Training loop\n",
    "    metrics_dict = {\n",
    "        \"Epoch\": [],\n",
    "        \"Train RMSE\": [],\n",
    "        \"Test RMSE\": [],\n",
    "    }\n",
    "\n",
    "    # Train loop\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        metrics_dict[\"Epoch\"].append(epoch)\n",
    "        for stage in ['train', 'test']:\n",
    "            with torch.set_grad_enabled(stage == 'train'): # Whether to start building a graph for a backward pass\n",
    "                if stage == 'train':\n",
    "                    model.train() # Enable some \"special\" layers (will speak about later)\n",
    "                else:\n",
    "                    model.eval() # Disable some \"special\" layers (will speak about later)\n",
    "\n",
    "                loss_at_stage = 0 \n",
    "                for batch in dls[stage]:\n",
    "                    batch = batch.to(DEVICE)\n",
    "                    x_pred = model(batch) # forward pass: model(x_batch) -> calls forward()\n",
    "                    loss = rmse_for_sparse(x_pred, batch) # ¡Important! y_pred is always the first arg\n",
    "                    if stage == \"train\":\n",
    "                        loss.backward() # Calculate the gradients of all the parameters wrt loss\n",
    "                        optimizer.step() # Update the parameters\n",
    "                        scheduler.step()\n",
    "                        optimizer.zero_grad() # Zero the saved gradient\n",
    "                    loss_at_stage += loss.item() * len(batch)\n",
    "                rmse_at_stage = (loss_at_stage / len(dls[stage].dataset)) ** (1/2)\n",
    "                metrics_dict[f\"{stage.title()} RMSE\"].append(rmse_at_stage)\n",
    "      \n",
    "    with torch.no_grad():\n",
    "        X_pred = model(torch.Tensor(X_test).to(DEVICE))\n",
    "\n",
    "    ae_recommender_model = AERecommender(X_pred, X_train, X_train)\n",
    "\n",
    "    ae_global_metrics = ae_recommender_model.evaluate()\n",
    "\n",
    "    metrics_dict[\"recall@5\"] = ae_global_metrics[\"recall@5\"]\n",
    "    metrics_dict[\"recall@10\"] = ae_global_metrics[\"recall@10\"]\n",
    "\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iYS06bYkA5uD",
   "metadata": {
    "id": "iYS06bYkA5uD"
   },
   "source": [
    "C изначальной архитектурой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "s69HDH9P-PZl",
   "metadata": {
    "id": "s69HDH9P-PZl"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_and_out_features = 8287):\n",
    "        super().__init__()\n",
    "        self.in_and_out_features = in_and_out_features\n",
    "        self.hidden_size = 500\n",
    "\n",
    "        self.sequential = nn.Sequential( \n",
    "            nn.Linear(in_and_out_features, self.hidden_size), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(self.hidden_size, in_and_out_features) # Another Linear transformation\n",
    "        )\n",
    "\n",
    "    def forward(self, x): # In the forward function, you define how your model runs, from input to output \n",
    "        x = self.sequential(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "TytUsH6vA9Wo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TytUsH6vA9Wo",
    "outputId": "464573c4-6c3f-4b04-ac32-3ea09fb84f08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:0.001 ne:0.001 bs:3000 ....\n",
      "lr:0.001 ne:0.001 bs:4500 ....\n",
      "lr:0.001 ne:0.001 bs:3000 ....\n",
      "lr:0.001 ne:0.001 bs:4500 ....\n",
      "lr:0.0003 ne:0.0003 bs:3000 ....\n",
      "lr:0.0003 ne:0.0003 bs:4500 ....\n",
      "lr:0.0003 ne:0.0003 bs:3000 ....\n",
      "lr:0.0003 ne:0.0003 bs:4500 ....\n"
     ]
    }
   ],
   "source": [
    "first_arch_metrics = {}\n",
    "\n",
    "for lr in [0.001, 0.0003]:\n",
    "  for ne in [100, 200]:\n",
    "    for bs in [3000, 4500]:\n",
    "        \n",
    "        print(f\"lr:{lr} ne:{lr} bs:{bs} ....\" )\n",
    "\n",
    "        LR = lr\n",
    "        NUM_EPOCHS = ne\n",
    "        BATCH_SIZE = bs\n",
    "\n",
    "        first_arch_metrics[f\"lr:{lr} ne:{ne} bs:{bs}\"] = train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "HnEm5GLZDAuC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HnEm5GLZDAuC",
    "outputId": "d652f3d6-c81a-4e35-e070-7350ce956120"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:0.001 ne:100 bs:3000 0.0856485318926931 0.24734999561176826\n",
      "lr:0.001 ne:100 bs:4500 0.08339590626737009 0.2456629642992969\n",
      "lr:0.001 ne:200 bs:3000 0.08698450466615308 0.2526061220708553\n",
      "lr:0.001 ne:200 bs:4500 0.0867699688923128 0.2529181741055321\n",
      "lr:0.0003 ne:100 bs:3000 0.08751109247467015 0.25363979443572215\n",
      "lr:0.0003 ne:100 bs:4500 0.08879830711771187 0.25470272167883995\n",
      "lr:0.0003 ne:200 bs:3000 0.08135781641588735 0.23005061093937415\n",
      "lr:0.0003 ne:200 bs:4500 0.08193316235482266 0.23188391664310024\n"
     ]
    }
   ],
   "source": [
    "for i in first_arch_metrics.keys():\n",
    "  print(i, first_arch_metrics[i]['recall@5'], first_arch_metrics[i]['recall@10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ZaDleIoiPyCJ",
   "metadata": {
    "id": "ZaDleIoiPyCJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "DOeEZG5_A9p4",
   "metadata": {
    "id": "DOeEZG5_A9p4"
   },
   "source": [
    "Усложним архитектуру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "rTOhYgiX-fEr",
   "metadata": {
    "id": "rTOhYgiX-fEr"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_and_out_features = 8287):\n",
    "        super().__init__()\n",
    "        self.in_and_out_features = in_and_out_features\n",
    "        self.hidden_size = 512\n",
    "\n",
    "        self.sequential = nn.Sequential( \n",
    "            nn.Linear(in_and_out_features, 4096), \n",
    "            nn.ReLU(), \n",
    "\n",
    "            nn.Linear(4096, self.hidden_size), \n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(self.hidden_size, 4096), \n",
    "            nn.ReLU(), \n",
    "\n",
    "            nn.Linear(4096, in_and_out_features) # Another Linear transformation\n",
    "        )\n",
    "\n",
    "    def forward(self, x): # In the forward function, you define how your model runs, from input to output \n",
    "        x = self.sequential(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "TPRykgiN-fNe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TPRykgiN-fNe",
    "outputId": "a32247b1-3a86-479d-aa0f-df75119e18e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:0.001 ne:100 bs:3000 ....\n",
      "lr:0.001 ne:100 bs:4500 ....\n",
      "lr:0.001 ne:200 bs:3000 ....\n",
      "lr:0.001 ne:200 bs:4500 ....\n",
      "lr:0.0003 ne:100 bs:3000 ....\n",
      "lr:0.0003 ne:100 bs:4500 ....\n",
      "lr:0.0003 ne:200 bs:3000 ....\n",
      "lr:0.0003 ne:200 bs:4500 ....\n"
     ]
    }
   ],
   "source": [
    "second_arch_metrics = {}\n",
    "\n",
    "for lr in [0.001, 0.0003]:\n",
    "  for ne in [100, 200]:\n",
    "    for bs in [3000, 4500]:\n",
    "        \n",
    "        print(f\"lr:{lr} ne:{ne} bs:{bs} ....\" )\n",
    "\n",
    "        LR = lr\n",
    "        NUM_EPOCHS = ne\n",
    "        BATCH_SIZE = bs\n",
    "\n",
    "        second_arch_metrics[f\"lr:{lr} ne:{ne} bs:{bs}\"] = train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "wMGBNnslD4ax",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wMGBNnslD4ax",
    "outputId": "76b97e64-342e-4ef5-b71e-f6a88c7daf36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:0.001 ne:100 bs:3000 0.14852701688006476 0.363608881781037\n",
      "lr:0.001 ne:100 bs:4500 0.14894633680166167 0.3632090651116074\n",
      "lr:0.001 ne:200 bs:3000 0.15524588725169922 0.35925965654772934\n",
      "lr:0.001 ne:200 bs:4500 0.1548265673301023 0.35853803621753927\n",
      "lr:0.0003 ne:100 bs:3000 0.15456327342584375 0.37245360663890703\n",
      "lr:0.0003 ne:100 bs:4500 0.15338332666972218 0.3731167172125952\n",
      "lr:0.0003 ne:200 bs:3000 0.15394892098257384 0.3672852448145728\n",
      "lr:0.0003 ne:200 bs:4500 0.1538026465913191 0.36697319277989604\n"
     ]
    }
   ],
   "source": [
    "for i in second_arch_metrics.keys():\n",
    "  print(i, second_arch_metrics[i]['recall@5'], second_arch_metrics[i]['recall@10'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k6zRyd-uD0Fy",
   "metadata": {
    "id": "k6zRyd-uD0Fy"
   },
   "source": [
    "Добавим еще слоев: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08GqJ7iu-fPo",
   "metadata": {
    "id": "08GqJ7iu-fPo"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_and_out_features = 8287):\n",
    "        super().__init__()\n",
    "        self.in_and_out_features = in_and_out_features\n",
    "        self.hidden_size = 512\n",
    "\n",
    "        self.sequential = nn.Sequential( \n",
    "            nn.Linear(in_and_out_features, 6000), \n",
    "            nn.ReLU(), \n",
    "\n",
    "            nn.Linear(6000, 3000), \n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(3000, 1024), \n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(1024, self.hidden_size), \n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(self.hidden_size, 1024), \n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(1024, 3000), \n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(3000, 6000), \n",
    "            nn.ReLU(), \n",
    "\n",
    "            nn.Linear(6000, in_and_out_features) # Another Linear transformation\n",
    "        )\n",
    "\n",
    "    def forward(self, x): # In the forward function, you define how your model runs, from input to output \n",
    "        x = self.sequential(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "AV4bbBpd-fSg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AV4bbBpd-fSg",
    "outputId": "2a985b96-d452-490b-d73c-419e0341b0d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:0.0003 ne:100 bs:3000 ....\n",
      "lr:0.0003 ne:100 bs:4500 ....\n",
      "lr:0.0003 ne:200 bs:3000 ....\n",
      "lr:0.0003 ne:200 bs:4500 ....\n"
     ]
    }
   ],
   "source": [
    "third_arch_metrics = {}\n",
    "\n",
    "for lr in [0.0003]:\n",
    "  for ne in [100, 200]:\n",
    "    for bs in [3000, 4500]:\n",
    "        \n",
    "        print(f\"lr:{lr} ne:{ne} bs:{bs} ....\" )\n",
    "\n",
    "        LR = lr\n",
    "        NUM_EPOCHS = ne\n",
    "        BATCH_SIZE = bs\n",
    "\n",
    "        third_arch_metrics[f\"lr:{lr} ne:{ne} bs:{bs}\"] = train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "v1gCEb8aFQc-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1gCEb8aFQc-",
    "outputId": "f7084cf6-b161-4951-cc6d-1abe32766205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:0.0003 ne:100 bs:3000 0.24635532975123603 0.6131237383833754\n",
      "lr:0.0003 ne:100 bs:4500 0.2430007703784606 0.6135430583049724\n",
      "lr:0.0003 ne:200 bs:3000 0.2589251757730602 0.6017533423698401\n",
      "lr:0.0003 ne:200 bs:4500 0.2589739339034784 0.6040157196212469\n"
     ]
    }
   ],
   "source": [
    "for i in third_arch_metrics.keys():\n",
    "  print(i, third_arch_metrics[i]['recall@5'], third_arch_metrics[i]['recall@10'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k0qGe8sVaZq4",
   "metadata": {
    "id": "k0qGe8sVaZq4"
   },
   "source": [
    "Модель обучена. Лучшей моделью является модель последней архитектуры , со следующими подобранными гипперпараметрам:\n",
    "\n",
    "*   LR: 0.0003\n",
    "*   NUM_EPOCHS: 200\n",
    "*   BATCH_SIZE: 4500\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sd7WVXXYo7H1",
   "metadata": {
    "id": "sd7WVXXYo7H1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
