{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport os\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:48:47.231413Z","iopub.execute_input":"2023-05-12T22:48:47.231892Z","iopub.status.idle":"2023-05-12T22:48:47.237485Z","shell.execute_reply.started":"2023-05-12T22:48:47.231855Z","shell.execute_reply":"2023-05-12T22:48:47.236396Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from IPython.display import display, clear_output\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:48:47.682215Z","iopub.execute_input":"2023-05-12T22:48:47.682686Z","iopub.status.idle":"2023-05-12T22:48:47.689656Z","shell.execute_reply.started":"2023-05-12T22:48:47.682644Z","shell.execute_reply":"2023-05-12T22:48:47.688761Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"interactions_df = pd.read_csv('/kaggle/input/kion-data/interactions_processed_kion.csv')\nusers_df = pd.read_csv('/kaggle/input/kion-data/users_processed_kion.csv')\nitems_df = pd.read_csv('/kaggle/input/kion-data/items_processed_kion.csv')","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:48:47.693309Z","iopub.execute_input":"2023-05-12T22:48:47.693989Z","iopub.status.idle":"2023-05-12T22:48:54.807146Z","shell.execute_reply.started":"2023-05-12T22:48:47.693957Z","shell.execute_reply":"2023-05-12T22:48:54.806142Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"interactions_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:48:54.808790Z","iopub.execute_input":"2023-05-12T22:48:54.809141Z","iopub.status.idle":"2023-05-12T22:48:54.831550Z","shell.execute_reply.started":"2023-05-12T22:48:54.809105Z","shell.execute_reply":"2023-05-12T22:48:54.830606Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   user_id  item_id last_watch_dt  total_dur  watched_pct\n0   176549     9506    2021-05-11       4250           72\n1   699317     1659    2021-05-29       8317          100\n2   656683     7107    2021-05-09         10            0\n3   864613     7638    2021-07-05      14483          100\n4   964868     9506    2021-04-30       6725          100","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>last_watch_dt</th>\n      <th>total_dur</th>\n      <th>watched_pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>176549</td>\n      <td>9506</td>\n      <td>2021-05-11</td>\n      <td>4250</td>\n      <td>72</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>699317</td>\n      <td>1659</td>\n      <td>2021-05-29</td>\n      <td>8317</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>656683</td>\n      <td>7107</td>\n      <td>2021-05-09</td>\n      <td>10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>864613</td>\n      <td>7638</td>\n      <td>2021-07-05</td>\n      <td>14483</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>964868</td>\n      <td>9506</td>\n      <td>2021-04-30</td>\n      <td>6725</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"interactions_df = interactions_df[interactions_df['last_watch_dt'] < '2021-04-01']","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:48:54.834258Z","iopub.execute_input":"2023-05-12T22:48:54.834612Z","iopub.status.idle":"2023-05-12T22:48:55.690950Z","shell.execute_reply.started":"2023-05-12T22:48:54.834566Z","shell.execute_reply":"2023-05-12T22:48:55.690018Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"interactions_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:48:55.692374Z","iopub.execute_input":"2023-05-12T22:48:55.692981Z","iopub.status.idle":"2023-05-12T22:48:55.699593Z","shell.execute_reply.started":"2023-05-12T22:48:55.692945Z","shell.execute_reply":"2023-05-12T22:48:55.698626Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(263874, 5)"},"metadata":{}}]},{"cell_type":"code","source":"users_interactions_count_df = interactions_df.groupby(['user_id', 'item_id']).size().groupby('user_id').size()\nprint('# users: %d' % len(users_interactions_count_df))\nusers_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['user_id']]\nprint('# users with at least 5 interactions: %d' % len(users_with_enough_interactions_df))","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:48:55.700970Z","iopub.execute_input":"2023-05-12T22:48:55.702897Z","iopub.status.idle":"2023-05-12T22:48:55.873164Z","shell.execute_reply.started":"2023-05-12T22:48:55.702865Z","shell.execute_reply":"2023-05-12T22:48:55.872192Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"# users: 86614\n# users with at least 5 interactions: 14563\n","output_type":"stream"}]},{"cell_type":"code","source":"print('# of interactions: %d' % len(interactions_df))\ninteractions_from_selected_users_df = interactions_df.merge(users_with_enough_interactions_df, \n               how = 'right',\n               left_on = 'user_id',\n               right_on = 'user_id')\nprint('# of interactions from users with at least 5 interactions: %d' % len(interactions_from_selected_users_df))","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:48:55.878474Z","iopub.execute_input":"2023-05-12T22:48:55.879153Z","iopub.status.idle":"2023-05-12T22:48:55.945009Z","shell.execute_reply.started":"2023-05-12T22:48:55.879114Z","shell.execute_reply":"2023-05-12T22:48:55.944114Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"# of interactions: 263874\n# of interactions from users with at least 5 interactions: 142670\n","output_type":"stream"}]},{"cell_type":"code","source":"import math","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:48:55.949616Z","iopub.execute_input":"2023-05-12T22:48:55.952538Z","iopub.status.idle":"2023-05-12T22:48:55.958947Z","shell.execute_reply.started":"2023-05-12T22:48:55.952499Z","shell.execute_reply":"2023-05-12T22:48:55.958039Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def smooth_user_preference(x):\n    return math.log(1+x, 2)\n    \ninteractions_full_df = interactions_from_selected_users_df \\\n                    .groupby(['user_id', 'item_id'])['watched_pct'].sum() \\\n                    .apply(smooth_user_preference).reset_index()\nprint('# of unique user/item interactions: %d' % len(interactions_full_df))\ninteractions_full_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:48:55.960433Z","iopub.execute_input":"2023-05-12T22:48:55.962718Z","iopub.status.idle":"2023-05-12T22:48:56.177145Z","shell.execute_reply.started":"2023-05-12T22:48:55.962683Z","shell.execute_reply":"2023-05-12T22:48:56.176276Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"# of unique user/item interactions: 142670\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"   user_id  item_id  watched_pct\n0       21      849     6.375039\n1       21     4345     6.658211\n2       21    10283     6.658211\n3       21    12261     6.658211\n4       21    15997     6.658211\n5       32      952     6.044394\n6       32     4382     4.954196\n7       32     4807     6.658211\n8       32    10436     6.658211\n9       32    12132     6.658211","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>watched_pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21</td>\n      <td>849</td>\n      <td>6.375039</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21</td>\n      <td>4345</td>\n      <td>6.658211</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21</td>\n      <td>10283</td>\n      <td>6.658211</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21</td>\n      <td>12261</td>\n      <td>6.658211</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>21</td>\n      <td>15997</td>\n      <td>6.658211</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>32</td>\n      <td>952</td>\n      <td>6.044394</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>32</td>\n      <td>4382</td>\n      <td>4.954196</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>32</td>\n      <td>4807</td>\n      <td>6.658211</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>32</td>\n      <td>10436</td>\n      <td>6.658211</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>32</td>\n      <td>12132</td>\n      <td>6.658211</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"interactions_train_df, interactions_test_df = train_test_split(interactions_full_df,\n                                   stratify=interactions_full_df['user_id'], \n                                   test_size=0.20,\n                                   random_state=42)\n\nprint('# interactions on Train set: %d' % len(interactions_train_df))\nprint('# interactions on Test set: %d' % len(interactions_test_df))","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:48:56.184268Z","iopub.execute_input":"2023-05-12T22:48:56.187298Z","iopub.status.idle":"2023-05-12T22:48:56.487677Z","shell.execute_reply.started":"2023-05-12T22:48:56.187263Z","shell.execute_reply":"2023-05-12T22:48:56.486704Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"# interactions on Train set: 114136\n# interactions on Test set: 28534\n","output_type":"stream"}]},{"cell_type":"code","source":"#Indexing by personId to speed up the searches during evaluation\ninteractions_full_indexed_df = interactions_full_df.set_index('user_id')\ninteractions_train_indexed_df = interactions_train_df.set_index('user_id')\ninteractions_test_indexed_df = interactions_test_df.set_index('user_id')","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:48:56.489058Z","iopub.execute_input":"2023-05-12T22:48:56.489942Z","iopub.status.idle":"2023-05-12T22:48:56.498700Z","shell.execute_reply.started":"2023-05-12T22:48:56.489906Z","shell.execute_reply":"2023-05-12T22:48:56.497752Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def get_items_interacted(person_id, interactions_df):\n    # Get the user's data and merge in the movie information.\n    interacted_items = interactions_df.loc[person_id]['item_id']\n    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:48:56.500269Z","iopub.execute_input":"2023-05-12T22:48:56.500930Z","iopub.status.idle":"2023-05-12T22:48:56.506091Z","shell.execute_reply.started":"2023-05-12T22:48:56.500896Z","shell.execute_reply":"2023-05-12T22:48:56.505080Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#Top-N accuracy metrics consts\nEVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n\nclass ModelEvaluator:\n\n\n    def get_not_interacted_items_sample(self, person_id, sample_size, seed=42):\n        interacted_items = get_items_interacted(person_id, interactions_full_indexed_df)\n        all_items = set(articles_df['item_id'])\n        non_interacted_items = all_items - interacted_items\n\n        random.seed(seed)\n        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n        return set(non_interacted_items_sample)\n\n    def _verify_hit_top_n(self, item_id, recommended_items, topn):        \n            try:\n                index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n            except:\n                index = -1\n            hit = int(index in range(0, topn))\n            return hit, index\n\n    def evaluate_model_for_user(self, model, person_id):\n        #Getting the items in test set\n        interacted_values_testset = interactions_test_indexed_df.loc[person_id]\n        if type(interacted_values_testset['item_id']) == pd.Series:\n            person_interacted_items_testset = set(interacted_values_testset['item_id'])\n        else:\n            person_interacted_items_testset = set([int(interacted_values_testset['item_id'])])  \n        interacted_items_count_testset = len(person_interacted_items_testset) \n\n        #Getting a ranked recommendation list from a model for a given user\n        person_recs_df = model.recommend_items(person_id, \n                                               items_to_ignore=get_items_interacted(person_id, \n                                                                                    interactions_train_indexed_df), \n                                               topn=10000000000)\n\n        hits_at_5_count = 0\n        hits_at_10_count = 0\n        #For each item the user has interacted in test set\n        for item_id in person_interacted_items_testset:\n            #Getting a random sample (100) items the user has not interacted \n            #(to represent items that are assumed to be no relevant to the user)\n            non_interacted_items_sample = self.get_not_interacted_items_sample(person_id, \n                                                                          sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS, \n                                                                          seed=item_id%(2**32))\n\n            #Combining the current interacted item with the 100 random items\n            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n\n            #Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n            valid_recs_df = person_recs_df[person_recs_df['item_id'].isin(items_to_filter_recs)]                    \n            valid_recs = valid_recs_df['item_id'].values\n            #Verifying if the current interacted item is among the Top-N recommended items\n            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n            hits_at_5_count += hit_at_5\n            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n            hits_at_10_count += hit_at_10\n\n        #Recall is the rate of the interacted items that are ranked among the Top-N recommended items, \n        #when mixed with a set of non-relevant items\n        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n\n        person_metrics = {'hits@5_count':hits_at_5_count, \n                          'hits@10_count':hits_at_10_count, \n                          'interacted_count': interacted_items_count_testset,\n                          'recall@5': recall_at_5,\n                          'recall@10': recall_at_10}\n        return person_metrics\n\n    def evaluate_model(self, model):\n        #print('Running evaluation for users')\n        people_metrics = []\n        for idx, person_id in enumerate(tqdm(list(interactions_test_indexed_df.index.unique().values))):\n            #if idx % 100 == 0 and idx > 0:\n            #    print('%d users processed' % idx)\n            person_metrics = self.evaluate_model_for_user(model, person_id)  \n            person_metrics['user_id'] = person_id\n            people_metrics.append(person_metrics)\n        print('%d users processed' % idx)\n\n        detailed_results_df = pd.DataFrame(people_metrics) \\\n                            .sort_values('interacted_count', ascending=False)\n        \n        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n        \n        global_metrics = {'modelName': model.get_model_name(),\n                          'recall@5': global_recall_at_5,\n                          'recall@10': global_recall_at_10}    \n        return global_metrics, detailed_results_df\n    \nmodel_evaluator = ModelEvaluator()    ","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:48:56.507547Z","iopub.execute_input":"2023-05-12T22:48:56.508164Z","iopub.status.idle":"2023-05-12T22:48:56.526992Z","shell.execute_reply.started":"2023-05-12T22:48:56.508130Z","shell.execute_reply":"2023-05-12T22:48:56.526149Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Constants\nSEED = 42 # random seed for reproducibility\nLR = 1e-3 # learning rate, controls the speed of the training\nWEIGHT_DECAY = 0.01 # lambda for L2 reg. ()\nNUM_EPOCHS = 200 # num training epochs (how many times each instance will be processed)\nGAMMA = 0.9995 # learning rate scheduler parameter\nBATCH_SIZE = 3000 # training batch size\nEVAL_BATCH_SIZE = 3000 # evaluation batch size.\nDEVICE = 'cuda' #'cuda' # device to make the calculations on","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:48:56.528401Z","iopub.execute_input":"2023-05-12T22:48:56.529041Z","iopub.status.idle":"2023-05-12T22:48:56.542434Z","shell.execute_reply.started":"2023-05-12T22:48:56.529009Z","shell.execute_reply":"2023-05-12T22:48:56.541500Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"total_df = interactions_train_df.append(interactions_test_indexed_df.reset_index())\ntotal_df['user_id'], users_keys = total_df.user_id.factorize()\ntotal_df['item_id'], items_keys = total_df.item_id.factorize()\n\ntrain_encoded = total_df.iloc[:len(interactions_train_df)].values\ntest_encoded = total_df.iloc[len(interactions_train_df):].values","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:48:56.545528Z","iopub.execute_input":"2023-05-12T22:48:56.545922Z","iopub.status.idle":"2023-05-12T22:48:56.570171Z","shell.execute_reply.started":"2023-05-12T22:48:56.545892Z","shell.execute_reply":"2023-05-12T22:48:56.569237Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_32/627896225.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  total_df = interactions_train_df.append(interactions_test_indexed_df.reset_index())\n","output_type":"stream"}]},{"cell_type":"code","source":"from scipy.sparse import csr_matrix\nshape = [int(total_df['user_id'].max()+1), int(total_df['item_id'].max()+1)]\nX_train = csr_matrix((train_encoded[:, 2], (train_encoded[:, 0], train_encoded[:, 1])), shape=shape).toarray()\nX_test = csr_matrix((test_encoded[:, 2], (test_encoded[:, 0], test_encoded[:, 1])), shape=shape).toarray()","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:48:56.571688Z","iopub.execute_input":"2023-05-12T22:48:56.572015Z","iopub.status.idle":"2023-05-12T22:48:56.993546Z","shell.execute_reply.started":"2023-05-12T22:48:56.571986Z","shell.execute_reply":"2023-05-12T22:48:56.992634Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Initialize the DataObject, which must return an element (features vector x and target value y)\n# for a given idx. This class must also have a length atribute\nclass UserOrientedDataset(Dataset):\n    def __init__(self, X):\n        super().__init__() # to initialize the parent class\n        self.X = X.astype(np.float32)\n        self.len = len(X)\n\n    def __len__(self): # We use __func__ for implementing in-built python functions\n        return self.len\n\n    def __getitem__(self, index):\n        return self.X[index]","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:48:56.994865Z","iopub.execute_input":"2023-05-12T22:48:56.995301Z","iopub.status.idle":"2023-05-12T22:48:57.002478Z","shell.execute_reply.started":"2023-05-12T22:48:56.995266Z","shell.execute_reply":"2023-05-12T22:48:57.001532Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Initialize DataLoaders - objects, which sample instances from DataObject-s\ntrain_dl = DataLoader(\n    UserOrientedDataset(X_train),\n    batch_size = BATCH_SIZE,\n    shuffle = True\n)\n\ntest_dl = DataLoader(\n    UserOrientedDataset(X_test),\n    batch_size = EVAL_BATCH_SIZE,\n    shuffle = False\n)\n\ndls = {'train': train_dl, 'test': test_dl}","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:48:57.004230Z","iopub.execute_input":"2023-05-12T22:48:57.005052Z","iopub.status.idle":"2023-05-12T22:48:57.769095Z","shell.execute_reply.started":"2023-05-12T22:48:57.005020Z","shell.execute_reply":"2023-05-12T22:48:57.768137Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, in_and_out_features=8287):\n        super().__init__()\n        self.in_and_out_features = in_and_out_features\n\n        self.encoder = nn.Sequential(\n            nn.Linear(in_and_out_features, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64)\n        )\n\n        self.decoder = nn.Sequential(\n            nn.Linear(64, 128),\n            nn.ReLU(),\n            nn.Linear(128, 256),\n            nn.ReLU(),\n            nn.Linear(256, 512),\n            nn.ReLU(),\n            nn.Linear(512, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, in_and_out_features)\n        )\n\n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:54:05.746326Z","iopub.execute_input":"2023-05-12T22:54:05.746716Z","iopub.status.idle":"2023-05-12T22:54:05.757672Z","shell.execute_reply.started":"2023-05-12T22:54:05.746682Z","shell.execute_reply":"2023-05-12T22:54:05.756614Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(SEED) # Fix random seed to have reproducible weights of model layers\n\nmodel = Model()\nmodel.to(DEVICE)\n\n# Initialize GD method, which will update the weights of the model\noptimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n# Initialize learning rate scheduler, which will decrease LR according to some rule\nscheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=GAMMA)\n\ndef rmse_for_sparse(x_pred, x_true):\n    mask = (x_true > 0)\n    sq_diff = (x_pred * mask - x_true) ** 2\n    mse = sq_diff.sum() / mask.sum()\n    return mse ** (1/2)","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:54:08.419766Z","iopub.execute_input":"2023-05-12T22:54:08.420122Z","iopub.status.idle":"2023-05-12T22:54:08.622768Z","shell.execute_reply.started":"2023-05-12T22:54:08.420090Z","shell.execute_reply":"2023-05-12T22:54:08.621825Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"import time\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:54:12.330792Z","iopub.execute_input":"2023-05-12T22:54:12.331521Z","iopub.status.idle":"2023-05-12T22:54:12.335394Z","shell.execute_reply.started":"2023-05-12T22:54:12.331488Z","shell.execute_reply":"2023-05-12T22:54:12.334503Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Training loop\nmetrics_dict = {\n    \"Epoch\": [],\n    \"Train RMSE\": [],\n    \"Test RMSE\": [],\n}\n\n# Train loop\nfor epoch in tqdm(range(NUM_EPOCHS)):\n    metrics_dict[\"Epoch\"].append(epoch)\n    for stage in tqdm(['train', 'test']):\n        with torch.set_grad_enabled(stage == 'train'): # Whether to start building a graph for a backward pass\n            if stage == 'train':\n                model.train() # Enable some \"special\" layers (will speak about later)\n            else:\n                model.eval() # Disable some \"special\" layers (will speak about later)\n\n            loss_at_stage = 0 \n            for batch in tqdm(dls[stage]):\n                batch = batch.to(DEVICE)\n                x_pred = model(batch) # forward pass: model(x_batch) -> calls forward()\n                loss = rmse_for_sparse(x_pred, batch) # ¡Important! y_pred is always the first arg\n                if stage == \"train\":\n                    loss.backward() # Calculate the gradients of all the parameters wrt loss\n                    optimizer.step() # Update the parameters\n                    scheduler.step()\n                    optimizer.zero_grad() # Zero the saved gradient\n                loss_at_stage += loss.item() * len(batch)\n            rmse_at_stage = (loss_at_stage / len(dls[stage].dataset)) ** (1/2)\n            metrics_dict[f\"{stage.title()} RMSE\"].append(rmse_at_stage)\n            \n    if (epoch == NUM_EPOCHS - 1) or epoch % 10 == 9:\n        clear_output(wait=True)\n        display(pd.DataFrame(metrics_dict))","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:54:14.818802Z","iopub.execute_input":"2023-05-12T22:54:14.819193Z","iopub.status.idle":"2023-05-12T22:59:29.499919Z","shell.execute_reply.started":"2023-05-12T22:54:14.819157Z","shell.execute_reply":"2023-05-12T22:59:29.498763Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"     Epoch  Train RMSE  Test RMSE\n0        0    2.324100   2.285075\n1        1    2.175688   1.908984\n2        2    1.919939   2.112832\n3        3    1.904753   1.827912\n4        4    1.709753   1.803653\n..     ...         ...        ...\n195    195    0.856014   1.509210\n196    196    0.851808   1.502118\n197    197    0.844854   1.512643\n198    198    0.838754   1.508177\n199    199    0.834080   1.512532\n\n[200 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Epoch</th>\n      <th>Train RMSE</th>\n      <th>Test RMSE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2.324100</td>\n      <td>2.285075</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2.175688</td>\n      <td>1.908984</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1.919939</td>\n      <td>2.112832</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1.904753</td>\n      <td>1.827912</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1.709753</td>\n      <td>1.803653</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>195</td>\n      <td>0.856014</td>\n      <td>1.509210</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>196</td>\n      <td>0.851808</td>\n      <td>1.502118</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>197</td>\n      <td>0.844854</td>\n      <td>1.512643</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>198</td>\n      <td>0.838754</td>\n      <td>1.508177</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>199</td>\n      <td>0.834080</td>\n      <td>1.512532</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 3 columns</p>\n</div>"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 200/200 [05:14<00:00,  1.57s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"with torch.no_grad():\n    X_pred = model(torch.Tensor(X_test).to('cuda:0'))\nX_pred","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:59:45.799840Z","iopub.execute_input":"2023-05-12T22:59:45.800323Z","iopub.status.idle":"2023-05-12T22:59:46.581597Z","shell.execute_reply.started":"2023-05-12T22:59:45.800277Z","shell.execute_reply":"2023-05-12T22:59:46.580562Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"tensor([[ 6.5228,  7.1596,  7.3687,  ...,  0.1101,  0.9299, -0.2915],\n        [ 0.6242,  2.1014,  1.1824,  ...,  0.0249,  0.1661, -0.0221],\n        [ 5.1198,  1.5680,  3.2636,  ..., -0.2532,  0.7326, -0.0617],\n        ...,\n        [ 1.3676,  3.1977,  1.2860,  ..., -0.0749,  0.2093,  0.0101],\n        [ 4.3195,  6.3940,  4.3129,  ...,  0.1390,  1.2582,  0.7444],\n        [ 5.5689,  6.5586,  7.5659,  ..., -0.0169,  0.8145, -0.3152]],\n       device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"class AERecommender:\n    \n    MODEL_NAME = 'Autoencoder'\n    \n    def __init__(self, X_preds, X_train_and_val, X_test):\n\n        self.X_preds = X_preds.cpu().detach().numpy()\n        self.X_train_and_val = X_train_and_val\n        self.X_test = X_test\n        \n    def get_model_name(self):\n        return self.MODEL_NAME\n        \n    def recommend_items(self, user_id, items_to_select_idx, topn=10, verbose=False):\n        user_preds = self.X_preds[user_id][items_to_select_idx]\n        items_idx = items_to_select_idx[np.argsort(-user_preds)[:topn]]\n\n        # Recommend the highest predicted rating movies that the user hasn't seen yet.\n        return items_idx\n\n    def evaluate(self, size=100):\n\n        X_total = self.X_train_and_val + self.X_test\n\n        true_5 = []\n        true_10 = []\n\n        for user_id in range(len(X_test)):\n            non_zero = np.argwhere(self.X_test[user_id] > 0).ravel()\n            all_nonzero = np.argwhere(X_total[user_id] > 0).ravel()\n            select_from = np.setdiff1d(np.arange(X_total.shape[1]), all_nonzero)\n\n            for non_zero_idx in non_zero:\n                random_non_interacted_100_items = np.random.choice(select_from, size=20, replace=False)\n                preds = self.recommend_items(user_id, np.append(random_non_interacted_100_items, non_zero_idx), topn=10)\n                true_5.append(non_zero_idx in preds[:5])\n                true_10.append(non_zero_idx in preds)\n\n        return {\"recall@5\": np.mean(true_5), \"recall@10\": np.mean(true_10)}\n    \nae_recommender_model = AERecommender(X_pred, X_train, X_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:59:49.423271Z","iopub.execute_input":"2023-05-12T22:59:49.423655Z","iopub.status.idle":"2023-05-12T22:59:49.825329Z","shell.execute_reply.started":"2023-05-12T22:59:49.423619Z","shell.execute_reply":"2023-05-12T22:59:49.824439Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"ae_global_metrics = ae_recommender_model.evaluate()\nae_global_metrics","metadata":{"execution":{"iopub.status.busy":"2023-05-12T22:59:52.955156Z","iopub.execute_input":"2023-05-12T22:59:52.955493Z","iopub.status.idle":"2023-05-12T23:00:17.190413Z","shell.execute_reply.started":"2023-05-12T22:59:52.955462Z","shell.execute_reply":"2023-05-12T23:00:17.189490Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"{'recall@5': 0.22565262757564825, 'recall@10': 0.5386505699825446}"},"metadata":{}}]}]}