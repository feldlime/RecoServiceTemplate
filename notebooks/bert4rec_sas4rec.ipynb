{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Нейросетевые рекомендации","metadata":{"id":"4950450a"}},{"cell_type":"markdown","source":"### Сравните качество Bert4Rec и Sas4Rec на данных КИОНа и выберите лучшую модель\n\n*   Проанализируйте воспроизводимость (10 баллов)\n*   Проанализируйте качество модели (8 баллов)","metadata":{"id":"237addfb"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import BertModel, BertTokenizer\nfrom sklearn.model_selection import KFold\n\nfrom pathlib import Path","metadata":{"id":"251203df","execution":{"iopub.status.busy":"2023-05-13T23:11:11.477578Z","iopub.execute_input":"2023-05-13T23:11:11.477976Z","iopub.status.idle":"2023-05-13T23:11:11.486115Z","shell.execute_reply.started":"2023-05-13T23:11:11.477945Z","shell.execute_reply":"2023-05-13T23:11:11.484929Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Data Processing","metadata":{"id":"mZbF12dzO4af"}},{"cell_type":"code","source":"interactions = pd.read_csv('/kaggle/input/kion-dataset/interactions.csv')\nusers = pd.read_csv('/kaggle/input/kion-dataset/users.csv')\nitems = pd.read_csv('/kaggle/input/kion-dataset/items.csv')","metadata":{"id":"V5XiXYYzCD9t","execution":{"iopub.status.busy":"2023-05-14T00:44:02.081536Z","iopub.execute_input":"2023-05-14T00:44:02.081909Z","iopub.status.idle":"2023-05-14T00:44:06.950593Z","shell.execute_reply.started":"2023-05-14T00:44:02.081879Z","shell.execute_reply":"2023-05-14T00:44:06.949544Z"},"trusted":true},"execution_count":183,"outputs":[]},{"cell_type":"code","source":"interactions = interactions.query(\"last_watch_dt >= '2021-07-15'\")","metadata":{"execution":{"iopub.status.busy":"2023-05-14T00:44:06.952824Z","iopub.execute_input":"2023-05-14T00:44:06.953499Z","iopub.status.idle":"2023-05-14T00:44:07.765783Z","shell.execute_reply.started":"2023-05-14T00:44:06.953459Z","shell.execute_reply":"2023-05-14T00:44:07.764860Z"},"trusted":true},"execution_count":184,"outputs":[]},{"cell_type":"code","source":"interactions['last_watch_dt'] = pd.to_datetime(interactions['last_watch_dt'])","metadata":{"id":"zYlznyi-CDr1","execution":{"iopub.status.busy":"2023-05-14T00:44:07.767211Z","iopub.execute_input":"2023-05-14T00:44:07.767588Z","iopub.status.idle":"2023-05-14T00:44:08.184938Z","shell.execute_reply.started":"2023-05-14T00:44:07.767552Z","shell.execute_reply":"2023-05-14T00:44:08.183959Z"},"trusted":true},"execution_count":185,"outputs":[]},{"cell_type":"code","source":"# Fill missing values with appropriate values or strategies\nusers['age'].fillna('unknown', inplace=True)\nusers['income'].fillna('unknown', inplace=True)\nusers['sex'].fillna('unknown', inplace=True)\n\nitems['release_year'].fillna(items['release_year'].median(), inplace=True)\nitems['countries'].fillna('unknown', inplace=True)\nitems['age_rating'].fillna(items['age_rating'].median(), inplace=True)\nitems['directors'].fillna('unknown', inplace=True)\nitems['actors'].fillna('unknown', inplace=True)\nitems['description'].fillna('unknown', inplace=True)\nitems['keywords'].fillna('unknown', inplace=True)\n","metadata":{"id":"kUS3oUk4K1BC","execution":{"iopub.status.busy":"2023-05-14T00:44:08.187904Z","iopub.execute_input":"2023-05-14T00:44:08.188319Z","iopub.status.idle":"2023-05-14T00:44:08.429091Z","shell.execute_reply.started":"2023-05-14T00:44:08.188281Z","shell.execute_reply":"2023-05-14T00:44:08.428135Z"},"trusted":true},"execution_count":186,"outputs":[]},{"cell_type":"code","source":"users = pd.get_dummies(users, columns=['age', 'income', 'sex'])","metadata":{"id":"M9G21xS9K34M","execution":{"iopub.status.busy":"2023-05-14T00:44:08.430474Z","iopub.execute_input":"2023-05-14T00:44:08.430816Z","iopub.status.idle":"2023-05-14T00:44:08.762377Z","shell.execute_reply.started":"2023-05-14T00:44:08.430783Z","shell.execute_reply":"2023-05-14T00:44:08.761274Z"},"trusted":true},"execution_count":187,"outputs":[]},{"cell_type":"code","source":"interactions = interactions.merge(users, on='user_id', how='left')\ninteractions['total_dur'] = (interactions['total_dur'] - interactions['total_dur'].mean()) / interactions['total_dur'].std()\nitem_id_mapping = {item_id: idx for idx, item_id in enumerate(items['item_id'].unique())}\ninteractions['item_index'] = interactions['item_id'].map(item_id_mapping)\n","metadata":{"id":"mIrlABO_K7z2","execution":{"iopub.status.busy":"2023-05-14T00:44:08.764287Z","iopub.execute_input":"2023-05-14T00:44:08.764716Z","iopub.status.idle":"2023-05-14T00:44:10.074680Z","shell.execute_reply.started":"2023-05-14T00:44:08.764678Z","shell.execute_reply":"2023-05-14T00:44:10.073754Z"},"trusted":true},"execution_count":188,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nclass InteractionDataset(Dataset):\n    def __init__(self, item_index, max_sequence_length):\n        self.sequences = self.create_padded_sequences(item_index, max_sequence_length)\n        self.masks = self.create_mask(self.sequences)\n\n    def __len__(self):\n        return len(self.sequences)\n\n    def __getitem__(self, index):\n        sequence = self.sequences[index]\n        mask = self.masks[index]\n        return torch.tensor(sequence, dtype=torch.long), torch.tensor(mask, dtype=torch.long)\n\n\n    def create_padded_sequences(self, item_index, max_length):\n        padded_sequences = []\n        for sequence in item_index:\n            sequence = [int(digit) for digit in str(sequence)]  # Convert integer to a list of digits\n            if len(sequence) < max_length:\n                sequence += [0] * (max_length - len(sequence))  # Pad the sequence with zeros\n            padded_sequences.append(sequence)\n        return padded_sequences\n\n    def create_mask(self, sequences):\n        masks = []\n        for sequence in sequences:\n            mask = [1 if item != 0 else 0 for item in sequence]\n            masks.append(mask)\n        return masks","metadata":{"id":"KP36TBcCCQJ3","execution":{"iopub.status.busy":"2023-05-14T00:44:10.076108Z","iopub.execute_input":"2023-05-14T00:44:10.076445Z","iopub.status.idle":"2023-05-14T00:44:10.086328Z","shell.execute_reply.started":"2023-05-14T00:44:10.076412Z","shell.execute_reply":"2023-05-14T00:44:10.085396Z"},"trusted":true},"execution_count":189,"outputs":[]},{"cell_type":"code","source":"# Assuming you have loaded your data into the following variables\nitem_index = interactions['item_index']\nmax_sequence_length = 5\n\n# Create InteractionDataset\ndataset = InteractionDataset(item_index, max_sequence_length)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T00:44:10.087486Z","iopub.execute_input":"2023-05-14T00:44:10.088530Z","iopub.status.idle":"2023-05-14T00:44:21.098523Z","shell.execute_reply.started":"2023-05-14T00:44:10.088496Z","shell.execute_reply":"2023-05-14T00:44:21.097443Z"},"trusted":true},"execution_count":190,"outputs":[]},{"cell_type":"code","source":"# Define the sizes for train, validation, and test sets\ntrain_size = int(0.7 * len(dataset))\nval_size = int(0.15 * len(dataset))\ntest_size = len(dataset) - train_size - val_size","metadata":{"execution":{"iopub.status.busy":"2023-05-14T00:44:21.100140Z","iopub.execute_input":"2023-05-14T00:44:21.100525Z","iopub.status.idle":"2023-05-14T00:44:21.106950Z","shell.execute_reply.started":"2023-05-14T00:44:21.100489Z","shell.execute_reply":"2023-05-14T00:44:21.105991Z"},"trusted":true},"execution_count":191,"outputs":[]},{"cell_type":"code","source":"# Split the dataset into train, validation, and test sets\ntrain_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n\n# Define batch size\nbatch_size = 32\n\n# Create data loaders for train, validation, and test sets\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\n","metadata":{"id":"RUETAbraObZV","execution":{"iopub.status.busy":"2023-05-14T00:44:21.110909Z","iopub.execute_input":"2023-05-14T00:44:21.111308Z","iopub.status.idle":"2023-05-14T00:44:21.548567Z","shell.execute_reply.started":"2023-05-14T00:44:21.111273Z","shell.execute_reply":"2023-05-14T00:44:21.547339Z"},"trusted":true},"execution_count":192,"outputs":[]},{"cell_type":"markdown","source":"## BERT4Rec","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import BertModel\nimport torch.nn as nn\n\nclass Bert4Rec(nn.Module):\n    def __init__(self, num_items, hidden_size=768, num_attention_heads=12, num_hidden_layers=6, dropout_prob=0.1):\n        super(Bert4Rec, self).__init__()\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\n        self.dropout = nn.Dropout(dropout_prob)\n        self.fc = nn.Linear(hidden_size, num_items)\n    \n    def forward(self, item_ids):\n        item_ids_embed = self.bert(item_ids)[0]  # Use the output of the first transformer layer\n        item_ids_embed = self.dropout(item_ids_embed)\n        logits = self.fc(item_ids_embed)\n        return logits\n","metadata":{"id":"cXbHPCPaCSVq","execution":{"iopub.status.busy":"2023-05-14T00:44:21.549915Z","iopub.execute_input":"2023-05-14T00:44:21.550323Z","iopub.status.idle":"2023-05-14T00:44:21.558425Z","shell.execute_reply.started":"2023-05-14T00:44:21.550267Z","shell.execute_reply":"2023-05-14T00:44:21.557448Z"},"trusted":true},"execution_count":193,"outputs":[]},{"cell_type":"code","source":"# Set the hyperparameters\n# batch_size = 32\nnum_items = len(train_loader)\nhidden_size = 768\nnum_layers = 2\nnum_heads = 4\ndropout = 0.1\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = BERT4Rec(num_items, hidden_size, num_layers, num_heads, dropout, device)\n","metadata":{"id":"bnObuNv4C0tl","execution":{"iopub.status.busy":"2023-05-14T00:44:21.559780Z","iopub.execute_input":"2023-05-14T00:44:21.560795Z","iopub.status.idle":"2023-05-14T00:44:24.058353Z","shell.execute_reply.started":"2023-05-14T00:44:21.560762Z","shell.execute_reply":"2023-05-14T00:44:24.057399Z"},"trusted":true},"execution_count":194,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"id":"uwHangi8C4os","execution":{"iopub.status.busy":"2023-05-14T00:44:24.059759Z","iopub.execute_input":"2023-05-14T00:44:24.060212Z","iopub.status.idle":"2023-05-14T00:44:24.067183Z","shell.execute_reply.started":"2023-05-14T00:44:24.060177Z","shell.execute_reply":"2023-05-14T00:44:24.066284Z"},"trusted":true},"execution_count":195,"outputs":[]},{"cell_type":"code","source":"import time\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-05-14T00:44:24.068550Z","iopub.execute_input":"2023-05-14T00:44:24.069517Z","iopub.status.idle":"2023-05-14T00:44:24.077184Z","shell.execute_reply.started":"2023-05-14T00:44:24.069483Z","shell.execute_reply":"2023-05-14T00:44:24.076288Z"},"trusted":true},"execution_count":196,"outputs":[]},{"cell_type":"code","source":"# Training loop\nnum_epochs = 1\nfor epoch in tqdm(range(1, num_epochs + 1)):\n    model.train()\n    total_loss = 0.0\n    for item_ids, masks in train_loader:\n        optimizer.zero_grad()\n        item_ids = item_ids.to(device)\n        masks = masks.to(device)\n        logits = model(item_ids, masks)  # Pass tensors directly to the model on the same device\n        logits_flat = logits.view(-1, logits.shape[-1])  # Reshape the logits tensor\n        item_ids_flat = item_ids.view(-1)[:logits_flat.size(0)]  # Reshape the item_ids tensor\n        loss = criterion(logits_flat, item_ids_flat)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    train_loss = total_loss / len(train_loader)\n\n    model.eval()\n    total_loss = 0.0\n    with torch.no_grad():\n        for item_ids, masks in val_loader:\n            item_ids = item_ids.to(device)\n            masks = masks.to(device)\n            logits = model(item_ids, masks)  # Pass tensors directly to the model on the same device\n            logits_flat = logits.view(-1, logits.shape[-1])  # Reshape the logits tensor\n            item_ids_flat = item_ids.view(-1)  # Reshape the item_ids tensor\n            loss = criterion(logits_flat, item_ids_flat)\n            total_loss += loss.item()\n    val_loss = total_loss / len(val_loader)\n\n    print(f\"Epoch {epoch}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"id":"VNnRCcNbC-iR","outputId":"c48aa492-51ce-4001-f8dd-189cfdd0930a","execution":{"iopub.status.busy":"2023-05-14T00:45:33.861157Z","iopub.execute_input":"2023-05-14T00:45:33.861550Z","iopub.status.idle":"2023-05-14T01:53:59.014002Z","shell.execute_reply.started":"2023-05-14T00:45:33.861519Z","shell.execute_reply":"2023-05-14T01:53:59.012021Z"},"trusted":true},"execution_count":198,"outputs":[{"name":"stderr","text":"  0%|          | 0/1 [1:08:25<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[198], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m         logits_flat \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, logits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# Reshape the logits tensor\u001b[39;00m\n\u001b[1;32m     27\u001b[0m         item_ids_flat \u001b[38;5;241m=\u001b[39m item_ids\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Reshape the item_ids tensor\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_ids_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m         total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     30\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(val_loader)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3028\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mValueError\u001b[0m: Expected input batch_size (32) to match target batch_size (160)."],"ename":"ValueError","evalue":"Expected input batch_size (32) to match target batch_size (160).","output_type":"error"}]},{"cell_type":"markdown","source":"## SAS4Rec","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\n\nclass SAS4Rec(nn.Module):\n    def __init__(self, num_items, embedding_size, hidden_size, num_attention_heads):\n        super(SAS4Rec, self).__init__()\n        self.num_items = num_items\n        self.embedding_size = embedding_size\n        self.hidden_size = hidden_size\n        self.num_attention_heads = num_attention_heads\n        \n        # Define the item embeddings\n        self.item_embeddings = nn.Embedding(num_items, embedding_size)\n        \n        # Define the self-attention mechanism\n        self.self_attention = nn.MultiheadAttention(embedding_size, num_attention_heads)\n        \n        # Define the feed-forward network\n        self.feed_forward = nn.Sequential(\n            nn.Linear(embedding_size, hidden_size),\n            nn.ReLU(),\n            nn.Linear(hidden_size, embedding_size)\n        )\n        \n    def forward(self, item_ids):\n        # Apply the item embeddings\n        item_embeddings = self.item_embeddings(item_ids)\n        # Transpose the item embeddings to match the shape expected by the self-attention module\n        item_embeddings = item_embeddings.permute(1, 0, 2)\n        # Apply the self-attention mechanism\n        output, _ = self.self_attention(item_embeddings, item_embeddings, item_embeddings)\n        # Transpose the output back to the original shape\n        output = output.permute(1, 0, 2)\n        # Apply the feed-forward network\n        output = self.feed_forward(output)\n        # Reshape the output to match the shape of the input item_ids\n        output = output.permute(0, 2, 1)\n        # Apply global max pooling to obtain a fixed-size representation\n        output = F.max_pool1d(output, output.size(2)).squeeze(2)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2023-05-14T01:53:59.015597Z","iopub.status.idle":"2023-05-14T01:53:59.016343Z","shell.execute_reply.started":"2023-05-14T01:53:59.016074Z","shell.execute_reply":"2023-05-14T01:53:59.016098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define hyperparameters\nembedding_size = 128\nhidden_size = 256\nnum_attention_heads = 4\nbatch_size = 32\nnum_epochs = 10\nlearning_rate = 0.001\n\n# Initialize the SAS4Rec model\nmodel = SAS4Rec(num_items, embedding_size, hidden_size, num_attention_heads)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T01:53:59.017689Z","iopub.status.idle":"2023-05-14T01:53:59.018391Z","shell.execute_reply.started":"2023-05-14T01:53:59.018134Z","shell.execute_reply":"2023-05-14T01:53:59.018158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move the model to the device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T01:53:59.019620Z","iopub.status.idle":"2023-05-14T01:53:59.020326Z","shell.execute_reply.started":"2023-05-14T01:53:59.020065Z","shell.execute_reply":"2023-05-14T01:53:59.020089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the loss function\ncriterion = nn.CrossEntropyLoss()\n# Define the optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T01:53:59.021647Z","iopub.status.idle":"2023-05-14T01:53:59.022443Z","shell.execute_reply.started":"2023-05-14T01:53:59.022147Z","shell.execute_reply":"2023-05-14T01:53:59.022175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for item_ids, masks in train_loader:\n    item_ids = item_ids.to(device)\n    logits = model(item_ids)\n    print(logits.shape)\n    logits_flat = logits.reshape(-1, logits.shape[-1])  # Reshape the logits tensor\n    print(logits_flat.shape)\n    item_ids_flat = item_ids.reshape(-1)[:logits_flat.size(0)]  # Reshape the item_ids tensor\n    print(item_ids_flat.shape)\n    #loss = criterion(logits_flat, item_ids_flat)\n    \n    break","metadata":{"execution":{"iopub.status.busy":"2023-05-14T01:53:59.023906Z","iopub.status.idle":"2023-05-14T01:53:59.024598Z","shell.execute_reply.started":"2023-05-14T01:53:59.024353Z","shell.execute_reply":"2023-05-14T01:53:59.024377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training loop\nnum_epochs = 1\nfor epoch in tqdm(range(1, num_epochs + 1)):\n    model.train()\n    total_loss = 0.0\n    for item_ids, masks in train_loader:\n        optimizer.zero_grad()\n        item_ids = item_ids.to(device)\n        masks = masks.to(device)\n        logits = model(item_ids)  # Pass tensors directly to the model on the same device\n        logits_flat = logits.reshape(-1, logits.shape[-1])  # Reshape the logits tensor\n        item_ids_flat = item_ids.reshape(-1)[:logits_flat.size(0)]  # Reshape the item_ids tensor\n        loss = criterion(logits_flat, item_ids_flat)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    train_loss = total_loss / len(train_loader)\n\n    model.eval()\n    total_loss = 0.0\n    with torch.no_grad():\n        for item_ids, masks in val_loader:\n            item_ids = item_ids.to(device)\n            masks = masks.to(device)\n            logits = model(item_ids)  # Pass tensors directly to the model on the same device\n            logits_flat = logits.reshape(-1, logits.shape[-1])  # Reshape the logits tensor\n            item_ids_flat = item_ids.reshape(-1)[:logits_flat.size(0)]  # Reshape the item_ids tensor\n            loss = criterion(logits_flat, item_ids_flat)\n            total_loss += loss.item()\n    val_loss = total_loss / len(val_loader)\n\n    print(f\"Epoch {epoch}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-14T01:53:59.025861Z","iopub.status.idle":"2023-05-14T01:53:59.026552Z","shell.execute_reply.started":"2023-05-14T01:53:59.026309Z","shell.execute_reply":"2023-05-14T01:53:59.026333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}